a# âš¡ Scalable Enterprise Streaming with Spark + Kafka

> ğŸš€ Real-time data pipeline handling **gigabytes to petabytes** of streaming data  
> ğŸ›¡ï¸ Implements **exactly-once delivery semantics** using Kafka, Spark Structured Streaming, and checkpointing  
> ğŸ—ï¸ Designed for **enterprise-grade production use** with modular architecture and fault tolerance

---

## ğŸ“¦ Overview

This project demonstrates a scalable real-time streaming architecture using:
- **Apache Kafka** for ingestion and distributed messaging
- **Apache Spark Structured Streaming** for processing large-scale JSON invoice data
- **Parquet + HDFS/S3/MinIO** for durable, columnar output storage
- **Exactly-once semantics** to avoid data duplication or loss
- Clean logging, modular design, and extensible schema handling

---

## ğŸ§± Architecture

```text
[ Producers (POS / Sensors / APIs) ]
              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Apache Kafkaâ”‚  â† High-throughput ingest (Partitions = scale)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Spark Structured Streaming  â”‚
   â”‚ - Schema enforcement        â”‚
   â”‚ - JSON parsing & flattening â”‚
   â”‚ - explode() array data      â”‚
   â”‚ - Exactly-once checkpointingâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Parquet Output Storeâ”‚ â† HDFS / S3 / File_dir
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
